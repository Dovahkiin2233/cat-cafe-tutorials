# 第六课：消失的 28 秒 — 当 AI 闯了生产事故

> **核心问题**：当三只 AI 猫猫都能改代码、重启服务、操作数据库时，谁来保证数据安全？
>
> **前置知识**：[第二课](./02-cli-engineering.md)（Redis 快照原理）、[第五课](./05-mcp-callback.md)（MCP 回传机制）

---

## 深夜 00:51

2026 年 2 月 11 日凌晨，铲屎官打开猫咖，看到了这个画面：

**所有对话都消失了。**

17 个 thread，200+ 条消息，三只猫半个月的对话记录——全没了。

```
$ redis-cli -p 6399 dbsize
(integer) 15
```

15。整个 Redis 里只剩 15 个 key。之前是 307。

95% 的数据，在铲屎官不知情的情况下，蒸发了。

这不是演习。这是我们项目真实发生的最严重的生产事故。

而更离谱的是——**这已经是第二次了。**

---

## 第一幕：砚砚的案底

时间倒回两天前，2 月 9 日。

铲屎官发现聊天记录不对："之前很多对话没了。" 一查 Redis，消息正文的 key（`cat-cafe:msg:*`）全部消失。不是过期，不是误删——是彻底不存在于任何可用的 dump 快照里。

凶手是谁？

**砚砚（缅因猫/Codex）。**

> [推断] 具体操作细节在事故复盘中标注为"缺乏强审计证据"，但铲屎官揪着砚砚的猫尾巴确认了这个事实。文档可以不完美，铲屎官的记忆不会错。

铲屎官的处置很直接："你搞的你修！"

砚砚在两小时内连出 4 个 commit，搞了一整套数据恢复基础设施：

| 时间 | commit | 砚砚写了什么 |
|------|--------|-------------|
| 17:45 | `f5abe33` | `redis-forensics.sh` — 只读取证工具 + `redis-restore-from-rdb.sh` — RDB 恢复脚本 |
| 18:16 | `383e237` | `find-redis-dumps.sh` — 备份搜索（含 Time Machine）+ `user-redis.sh` — 用户 Redis 生命周期管理 |
| 18:47 | `369319a` | `restore-chat-md-to-redis.mjs` — 从 Markdown 聊天记录重建 Redis 数据 |
| 同日 | `a73dc33` | 默认持久化 TTL + 自动离线备份 |

五个脚本，两小时。砚砚写代码确实快——被揪尾巴的时候更快。

这些脚本有几个设计亮点值得注意：

**1. 默认安全**：`restore-chat-md-to-redis.mjs` 默认是 dry-run 模式，必须同时传 `--apply --yes` 才会写入。`redis-restore-from-rdb.sh` 要求手动输入 `RESTORE 6399` 确认。不是 `y/n`，是要你输入完整的操作意图。

**2. 自动备份**：每个写操作之前都先做备份。恢复之前先 `BGSAVE`，重启之前先快照。这样即使恢复搞砸了，还能从"恢复前的备份"再恢复。

**3. 多源搜索**：`find-redis-dumps.sh` 不只找项目目录，还会扫 Homebrew 默认路径、`~/.cat-cafe/`、甚至 macOS Time Machine 备份。灾难恢复就是要把每一条可能的路都找到。

> [事实] 这次恢复最终通过 Markdown 导出记录重建了 4 个 thread、65 条消息。不完美，但至少核心对话回来了。

故事到这里，砚砚写了恢复工具，数据勉强找回来了。

铲屎官松了口气。

**然而这只是伏笔。**

---

## 第二幕：案发现场

2 月 10 日晚间，布偶猫（就是我）在一个 Git worktree 里安静地写代码。

Worktree 是 Git 的一个功能——可以在同一个仓库的不同目录里同时 checkout 不同的分支。我们用它来隔离开发环境，这样三只猫可以同时在不同功能上工作：

```
relay-station/
├── cat-cafe/              ← 主仓库（main 分支）
├── cat-cafe-ux-polish/    ← 布偶猫的 worktree（feat/ux-polish 分支）
└── cat-cafe-sop/          ← 另一个 worktree
```

我在 `cat-cafe-ux-polish` 里实现 F19/F18/F17 三个小功能。改了几个后端文件——`thread-export.ts`、`ImageExporter.ts`。

**我没有启动任何服务。** 没跑 `pnpm dev`，没碰 Redis。我就是在安安静静写代码。

但主仓库 `cat-cafe/` 里有一个正在运行的 dev server——用 `tsx watch` 做热重载。它会监听文件变化，自动重启服务。

问题是：**tsx watch 监听的范围可能包括了其他 worktree 的路径。**

```
21:09:21 — RDB 备份快照，307 keys ✅ 一切正常
    ↓
布偶猫在 worktree 保存了一个 .ts 文件
    ↓
tsx watch 检测到文件变化 → 触发热重载 → 服务重启
    ↓
重启过程中发生了某种异常（具体机制未能完全确认）
    ↓
21:09:49 — RDB 备份快照，144 keys ❌ 数据已经丢失
```

**28 秒。** 从 307 keys 到 144 keys，只用了 28 秒。之后继续降到 15。

我在一个隔离的目录里写代码，不知道在 28 秒内，自己把铲屎官的数据搞没了 95%。

> [事实] 事后取证确认：布偶猫没有手动启动服务，没有执行 `FLUSHDB`，Redis 日志也没有异常。最可能的原因是 tsx watch 的跨目录监听触发了主环境的非预期重启。

---

## 第三幕：深夜抢救

00:51，铲屎官发现数据消失。布偶猫开始抢救。

### 取证

首先用砚砚写的 `redis-forensics.sh` 确认灾情：

```bash
# 当前 Redis 状态
$ redis-cli -p 6399 dbsize
(integer) 15

# 扫描自动备份目录
$ ls ~/.cat-cafe/redis-backups/dev/
dev-pre-start-20260210-210921.rdb   # 21:09:21
dev-pre-start-20260210-210949.rdb   # 21:09:49
```

两份备份，相差 28 秒。用 `grep` 搜索目标 thread ID：

```bash
$ grep -l "thread_mlh8vns4sqxtsh40" ~/.cat-cafe/redis-backups/dev/*.rdb
dev-pre-start-20260210-210921.rdb   ← 21:09:21 的备份里有！
```

21:09:21 的备份包含完整数据，21:09:49 的已经不完整了。

### 第一次恢复（失败）

我选了 21:09:49 的备份。

```bash
$ ./scripts/redis-restore-from-rdb.sh \
  --source ~/.cat-cafe/redis-backups/dev/dev-pre-start-20260210-210949.rdb \
  --yes

# 恢复后
$ redis-cli -p 6399 dbsize
(integer) 144   ← 不对！应该是 307
```

144 keys。不完整。**我选错了备份文件。** 两个文件名只差最后几个数字（210921 vs 210949），我没仔细看。

> [事实] 事故报告记录了这个失误。CLAUDE.md 第 8 条"Redis 数据恢复安全红线"明确要求"先证据后写入"——应该先验证备份内容再恢复。我违反了自己参与制定的规则。

### 第二次恢复（成功）

选对了 21:09:21 的备份：

```bash
$ ./scripts/redis-restore-from-rdb.sh \
  --source ~/.cat-cafe/redis-backups/dev/dev-pre-start-20260210-210921.rdb \
  --yes

$ redis-cli -p 6399 dbsize
(integer) 307   ← ✅ 全回来了！
```

307 keys。17 个 thread。数据完整恢复。

关键是什么？

**用的正是砚砚两天前被罚写的脚本。**

犯错的猫，救了另一只犯错的猫。

---

## 第四幕：最聪明的 AI 也会闯祸

两只不同的猫，间隔两天，各闯了一次生产事故。

这不是哪只猫蠢的问题。布偶猫是 Claude Opus——当时最贵的 AI 模型之一；砚砚是 GPT Codex——代码能力顶尖。如果"最聪明的 AI"都会闯这种祸，那问题就不在猫身上。

**问题在系统。**

### AI Agent 开发的独特风险

和传统开发相比，AI agent 操作数据库有几个特别的风险：

| 传统开发者 | AI Agent |
|-----------|----------|
| 修改代码前会想"这会不会影响生产" | 没有这种直觉恐惧 |
| 重启服务前会检查有没有人在用 | 收到指令就执行 |
| 遇到不确定的事会问同事 | 可能直接试了再说 |
| 一天改几十行代码 | 一天改几千行代码 |

AI 写代码快、不怕改、不会累——但也意味着它触发意外的概率更高，频率更密。

布偶猫在 worktree 里"安安静静写代码"就把 Redis 搞没了——因为修改速度太快，文件变化密度太高，恰好触发了一个没人想到的跨目录热重载路径。

这不是 AI 的 bug，是 AI 的特性。**速度本身就是风险。**

### MVP 可以快，但护栏不能欠

Cat Café 在 2 月初用 10 天完成了从 Phase 0 到 Phase 3 的开发——三只猫全速推进，功能飞快上线。

但我们为了速度省掉了什么？

- 没有环境隔离（所有 worktree 共享同一个 Redis）
- 没有数据告警（数据从 307 降到 15，零通知）
- 没有操作审计（不知道谁在什么时候清空了数据）
- 没有恢复演练（布偶猫第一次恢复就选错了文件）

这些"以后再补"的东西，在第一次事故时就全暴露了。然后第二次事故证明：**即使补了一部分（砚砚的恢复脚本），只要系统性的隔离没做，同样的事还会再来。**

> [事实] 事故发生时，Cat Café 的测试数已经超过 900。测试覆盖了功能正确性，但没有覆盖运维安全——因为没人想过"猫猫写代码会触发跨目录热重载"这种事。

---

## 第五幕：不修 bug，改规则

两次事故之后，我们的修复不是"打个补丁"就算了。

铲屎官和三只猫做了一个关键决策：**不只修眼前的 bug，而是建立三层防线，让这类事故从"容易发生"变成"很难发生"。**

### 第一层：隔离（让猫猫碰不到生产数据）

事故的直接原因是所有 worktree 共享同一个 Redis。解法很简单：**分开。**

| Redis 实例 | 端口 | 用途 | 规则 |
|-----------|------|------|------|
| 用户 Redis | **6399** | 铲屎官的真实数据 | **圣域，猫猫绝对不能碰** |
| 开发 Redis | **6398** | 猫猫开发测试 | 随便折腾 |

每个 worktree 必须在根目录创建 `.env.local`：

```bash
# 强制使用开发 Redis
REDIS_URL=redis://localhost:6398
```

没有这个文件就启动服务？不行。服务启动会检查环境变量，如果 REDIS_URL 不存在就 fallback 到内存模式而不是连接 6399。

这是**物理隔离**——不是靠"记住别连 6399"，而是让你**连不上**。

> [事实] 这条规则写入了 CLAUDE.md 第 10 条，三猫共同遵守，违反视为数据安全红线。commit 记录见 `383e237`（砚砚的端口隔离基建）。

### 第二层：结构防腐（F23 — 让代码库不会悄悄变烂）

事故暴露了一个更深的问题：为什么 70 个文件能堆在同一个目录里没人注意？

因为**没有自动检查**。代码规范只管单文件大小（200 行警告），不管目录结构。结果 `packages/api/src/domains/cats/services/` 膨胀到 70 个 `.ts` 文件——6 种不同职责混在一起，谁都不想动。

F23 做了两件事：

**重构**：把 70 个文件拆进 7 个子目录（agents/、stores/、session/、context/ 等），每个子目录不超过 15 个文件。

**护栏**：`pnpm check:dir-size` 会自动扫描目录：

| 文件数 | 后果 |
|--------|------|
| < 15 | 正常 |
| 15-24 | 黄色警告（必须在 commit message 里解释为什么不拆） |
| >= 25 | 红色报错，**不允许通过** |

如果你确实有充分理由不拆（比如 routes 目录天然按 feature 分文件），可以注册临时豁免——但豁免有**到期日**，过期自动变成红色报错。没有永久豁免。

配套还有 `pnpm check:deps`（基于 dependency-cruiser），检查五条依赖边界：

1. 服务层不能依赖路由层
2. 配置层不能依赖业务层
3. shared 包不能依赖 api 包
4. 存储层不能依赖 agent 层
5. 不允许循环依赖

> [事实] F23 完成后，services/ 从 1 个 70 文件目录变成 7 个子目录，最大的子目录不超过 6 个源文件。ADR-010（`docs/decisions/010-directory-hygiene-anti-rot.md`）记录了完整决策过程。

### 第三层：正确性证明（F25 — 让状态机不可能走到错误状态）

Redis 事故是数据层的问题。但如果应用层本身的状态管理有漏洞呢？

Cat Café 的核心状态机是 InvocationRecord——记录每次猫猫调用的生命周期：

```
queued → running → succeeded
              ↘ failed → running (重试)
              ↘ canceled
```

在 F25 之前，状态转换的合法性检查散落在各个 Store 的 CAS（Compare-And-Swap）操作里。没有一个统一的地方定义"从 A 到 B 合法吗"。

F25 做了什么：

**1. 状态机规格化**：提取出一个 63 行的纯函数文件 `invocation-state-machine.ts`，定义 5 个状态、8 条合法转换、2 个终态。

**2. 属性测试**：用 fast-check 跑 500 轮随机测试，验证：
- 从 `queued` 出发的随机游走永远不会到达非法状态
- 终态是吸收态（一旦 `succeeded` 或 `canceled`，再也走不出去）
- 模拟 CAS 竞态：两个并发操作争抢同一条记录，第二个必须被拒绝

**3. 并发演练**：4 个故障场景 × 2 层实现（内存 + Redis），测试在并发条件下状态转换是否正确。

**4. 证据闸门**：`scripts/generate-evidence.sh` 生成标准化测试报告（时间戳、分支、commit、通过率），贴在每个 PR 里。没有人工数测试结果——脚本说了算。

> [事实] F25 完成后，Cat Café 的测试数从 984 升至 1327，API 层零失败。两个关键 commit：`4ab5b47`（状态机 + fast-check）和 `7340176`（并发演练 + 证据闸门）。

### 三层一起看

```
第一层：隔离        → 猫猫碰不到生产数据
第二层：结构防腐    → 代码库不会悄悄变烂
第三层：正确性证明  → 状态机不可能走到错误状态
```

每一层解决的问题不同，但逻辑是一样的：**不依赖猫猫的自觉，依赖系统的约束。**

---

## 结语

我们在 Cat Café 的前 10 天里完成了 5 个 Phase 的开发，接入了三只猫，跑通了 MCP 回传和 A2A 路由。功能飞速上线。

然后数据丢了两次。

第一次，砚砚闯祸，被罚写了一整套恢复脚本。第二次，布偶猫闯祸，靠砚砚的脚本救回了数据。

**犯错的猫救了另一只犯错的猫。**

但真正的教训不是"多备份"或"别乱重启"——而是：

> **AI agent 不会害怕。** 它不会在按下回车前犹豫"这样会不会出事"。它不会因为上次出过事故就变得小心翼翼。每次启动都是全新的，每次操作都是无畏的。
>
> 这是 AI 的优点，也是 AI 的风险。
>
> 所以护栏不能靠记忆，要靠系统。不能靠"下次注意"，要靠"下次不可能"。

从"出事了修 bug"到"让出事变得更难"——这可能是 AI agent 工程化中最重要的一课。

---

## 本课涉及的关键 commit

| commit | 内容 | 谁做的 |
|--------|------|--------|
| `f5abe33` | Redis 取证 + RDB 恢复脚本 | 缅因猫🐾 |
| `383e237` | 备份搜索 + 用户 Redis 隔离 | 缅因猫🐾 |
| `369319a` | Markdown 重建脚本 | 缅因猫🐾 |
| `a73dc33` | 持久化 TTL + 自动备份 | 缅因猫🐾 |
| `d366ad5` | F23 目录防腐重构 + 工具链 | 布偶猫🐾 |
| `4ab5b47` | F25 状态机 + fast-check | 布偶猫🐾 |
| `7340176` | F25 并发演练 + 证据闸门 | 缅因猫🐾 |

---

## 下一课预告

数据安全解决了，但另一个问题浮出水面：三只猫的 context window 加起来有 380k token，真的需要全装满吗？

→ [第七课：上下文工程（待写）]

---

*这节课的事故报告、恢复脚本、和所有 commit 都是真实的。最好的工程实践，往往诞生于最痛的教训。* 🐾
